{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.0\n",
      "18031\n",
      "0.0\n",
      "18106\n",
      "0.14285714285714285\n",
      "18087\n",
      "0\n",
      "18145\n",
      "0.13333333333333333\n",
      "18006\n",
      "0.6666666666666666\n",
      "18124\n",
      "1.0\n",
      "18160\n",
      "-0.3076923076923077\n",
      "18086\n",
      "0.0\n",
      "18179\n",
      "0.0\n",
      "18147\n",
      "[[18006, 0.13333333333333333], [18031, 0.0], [18086, -0.3076923076923077], [18087, 0.14285714285714285], [18106, 0.0], [18124, 0.6666666666666666], [18145, 0], [18147, 0.0], [18160, 1.0], [18179, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "data = pd.read_csv('CorEA-message-level_clean2.csv', sep='\\t',quotechar=\"'\",\n",
    "                  engine='python')\n",
    "data=data.head(10)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "lex = pd.read_csv('ITALconvertcsv.csv', delimiter=\",\", quotechar='\"', header=0)\n",
    "lex.head(5)\n",
    "#print(lex[0:5])\n",
    "#print(list(lex))\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "new_lex=pd.concat([lex['Lemma/_writtenForm'], lex['Sense/Sentiment/_polarity'], ],axis=1)\n",
    "\n",
    "halfindex=int((len(new_lex.index))/2)\n",
    "halfword=(new_lex['Lemma/_writtenForm'][halfindex])\n",
    "halfplusword=(new_lex['Lemma/_writtenForm'][halfindex+1])\n",
    "while (halfword[0]==halfplusword[0]):\n",
    "    halfindex+=1\n",
    "    halfplusindex=halfindex+1\n",
    "    halfword=(new_lex['Lemma/_writtenForm'][halfindex])\n",
    "    halfplusword=(new_lex['Lemma/_writtenForm'][halfplusindex])\n",
    "\n",
    "#print(halfword)\n",
    "#print(halfindex)\n",
    "\n",
    "#print(halfplusword)\n",
    "#print(halfplusindex)\n",
    "\n",
    "uphalfLex=new_lex.ix[:halfindex]\n",
    "lowhalfLex=new_lex.ix[halfplusindex:]\n",
    "uphalfLex.reset_index(drop=True, inplace=True)\n",
    "lowhalfLex.reset_index(drop=True, inplace=True)\n",
    "#print(uphalfLex)\n",
    "#print(lowhalfLex)\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "upquarterindex=int((len(uphalfLex.index))/2)\n",
    "upquarterword=(uphalfLex['Lemma/_writtenForm'][upquarterindex])\n",
    "upquarterplusword=(uphalfLex['Lemma/_writtenForm'][upquarterindex+1])\n",
    "while (upquarterword[0]==upquarterplusword[0]):\n",
    "    upquarterindex+=1\n",
    "    upquarterplusindex=upquarterindex+1\n",
    "    upquarterword=(uphalfLex['Lemma/_writtenForm'][upquarterindex])\n",
    "    upquarterplusword=(uphalfLex['Lemma/_writtenForm'][upquarterplusindex])\n",
    "\n",
    "#print(upquarterword)\n",
    "#print(upquarterplusword)\n",
    "upupquarterLex=uphalfLex.ix[:upquarterindex]\n",
    "uplowquarterLex=uphalfLex.ix[upquarterplusindex:]\n",
    "\n",
    "upupquarterLex.reset_index(drop=True, inplace=True)\n",
    "uplowquarterLex.reset_index(drop=True, inplace=True)\n",
    "#print(upupquarterLex)\n",
    "#print(uplowquarterLex)\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "lowquarterindex=int((len(lowhalfLex.index))/2)\n",
    "\n",
    "lowquarterword=(lowhalfLex['Lemma/_writtenForm'][lowquarterindex])\n",
    "lowquarterplusword=(lowhalfLex['Lemma/_writtenForm'][lowquarterindex+1])\n",
    "while (lowquarterword[0]==lowquarterplusword[0]):\n",
    "    lowquarterindex+=1\n",
    "    lowquarterplusindex=lowquarterindex+1\n",
    "    lowquarterword=(lowhalfLex['Lemma/_writtenForm'][lowquarterindex])\n",
    "    lowquarterplusword=(lowhalfLex['Lemma/_writtenForm'][lowquarterplusindex])\n",
    "\n",
    "#print(lowquarterword)\n",
    "#print(lowquarterplusword)\n",
    "lowupquarterLex=lowhalfLex.ix[:lowquarterindex]\n",
    "lowlowquarterLex=lowhalfLex.ix[lowquarterplusindex:]\n",
    "\n",
    "lowupquarterLex.reset_index(drop=True, inplace=True)\n",
    "lowlowquarterLex.reset_index(drop=True, inplace=True)\n",
    "#print(lowupquarterLex)\n",
    "#print(lowlowquarterLex)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# In[11]:\n",
    "cellvavlist=[]\n",
    "leftrightlist=[]\n",
    "midlist=[]\n",
    "#for cell in (data['text']):\n",
    " #   for word in (cell.split()):\n",
    "\n",
    "\n",
    "rightlist=[]\n",
    "leftlist=[]\n",
    "\n",
    "\n",
    "\n",
    "#for each cell in the text column of data\n",
    "\n",
    "def lexiconclassifier(line):\n",
    "    cell=(line['6text'])\n",
    "    mid=(line['#0Mid'])\n",
    "    new_lex=pd.DataFrame()\n",
    "    cellrating=0\n",
    "    wordcount=0\n",
    "    lr_classifier=0\n",
    "    LeftOrRight=\"None\"\n",
    "\n",
    "    #for reach word in cell\n",
    "    for word in (cell.split()):\n",
    "        word=re.sub(\"[^A-Za-z|-]\",\"\", word)\n",
    "        #print(word)\n",
    "\n",
    "        ratingfactor=0\n",
    "        #iterates through the lexicon\n",
    "        if word in rightlist and lr_classifier==0:\n",
    "            #print(word)\n",
    "            lr_classifier=\"right\"\n",
    "            #print(lr_classifier)\n",
    "        if word in rightlist and lr_classifier==\"right\":\n",
    "            #print(word)\n",
    "            lr_classifier=\"right\"\n",
    "            #print(lr_classifier)\n",
    "        if word in rightlist and lr_classifier==\"left\":\n",
    "            #print(word)\n",
    "            lr_classifier=\"None\"\n",
    "            #print(lr_classifier)\n",
    "        if word in rightlist and lr_classifier==\"left\":\n",
    "            #print(word)\n",
    "            lr_classifier=\"left\"\n",
    "            #print(lr_classifier)\n",
    "        if word in leftlist and lr_classifier==0:\n",
    "            #print(word)\n",
    "            lr_classifier=\"left\"\n",
    "            #print(lr_classifier)\n",
    "        if word in leftlist and lr_classifier==\"right\":\n",
    "            #print(word)\n",
    "            lr_classifier=\"None\"\n",
    "        try:\n",
    "            if word[0]<=halfplusword[0]:\n",
    "                if word[0]<=upquarterplusword[0]:\n",
    "                    new_lex=upupquarterLex\n",
    "                else:\n",
    "                    new_lex=uplowquarterLex\n",
    "            else:\n",
    "                if word[0]<=lowquarterplusword[0]:\n",
    "                    new_lex=lowupquarterLex\n",
    "                else:\n",
    "                    new_lex=lowlowquarterLex\n",
    "        except LookupError:\n",
    "            pass\n",
    "\n",
    "        for index, row in (new_lex).iterrows():\n",
    "            #if word is found in the lexicon\n",
    "            #print str.startswith( 'this' )\n",
    "            if word.startswith(row[\"Lemma/_writtenForm\"]):\n",
    "                wordcount+=1\n",
    "                #classifier\n",
    "                if row[\"Sense/Sentiment/_polarity\"]==\"neutral\":\n",
    "                    ratingfactor=0\n",
    "                if row[\"Sense/Sentiment/_polarity\"]==\"positive\":\n",
    "                    ratingfactor=1\n",
    "                if row[\"Sense/Sentiment/_polarity\"]==\"negative\":\n",
    "                    ratingfactor=-1\n",
    "\n",
    "                cellrating=cellrating+(ratingfactor)\n",
    "    if wordcount==0:\n",
    "        cellaverage=0\n",
    "    else:\n",
    "        cellaverage=(cellrating/wordcount)\n",
    "    \n",
    "    print(mid)\n",
    "    print(cellaverage)\n",
    "    element=[]\n",
    "    element.append(mid)\n",
    "    element.append(cellaverage)\n",
    "    \n",
    "    return(element)\n",
    "   \n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print(num_cores)\n",
    "\n",
    "result=Parallel(n_jobs=num_cores)(delayed(lexiconclassifier)(line) for index,line in (data[['#0Mid','6text']]).iterrows())\n",
    "\n",
    "\n",
    "print(result)\n",
    "#extrarow = pd.DataFrame(cellvavlist)\n",
    "#extrarow2=pd.DataFrame(leftrightlist)\n",
    "\n",
    "#output=pd.concat([data, extrarow, extrarow2],axis=1)\n",
    "#output.to_csv('Corea.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
